{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pré processa os dados os dados do arquivo separando em dois dicionarios de mensagens;\n",
    "Um chaveado pela data de envio das mensagens;\n",
    "Um chaveado pelo autor das mensagens.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open('_chat.txt', 'r') as f:\n",
    "    data = []\n",
    "    lines = [line.strip() for line in f.readlines()[6:]]\n",
    "\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            try:\n",
    "                date = line.split('[')[1].split()[0]\n",
    "            except:\n",
    "                continue\n",
    "            try:\n",
    "                user = line.split(']')[1].split(':')[0].strip()\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                message = line.split(':')[3].strip()\n",
    "            except:\n",
    "                continue\n",
    "            data.append((date, user, message))\n",
    "\n",
    "name_dict = {}\n",
    "date_dict = {}\n",
    "for log in data:\n",
    "    # por nome\n",
    "    if log[1] in name_dict.keys():\n",
    "        name_dict[log[1]].append(log[2])\n",
    "    else:\n",
    "        name_dict[log[1]] = [log[2]]\n",
    "\n",
    "    # por data\n",
    "    if log[0] in date_dict.keys():\n",
    "        date_dict[log[0]].append(log[2])\n",
    "    else:\n",
    "        date_dict[log[0]] = [log[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470 470\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Vetoriza os textos de dois membros.\n",
    "Separa a mesma quantidade em cada vetor\n",
    "\"\"\"\n",
    "bruno = [vectorizer(text).vector for text in name_dict['Beelzebruno'] if 'sticker' not in text and 'image' not in text]\n",
    "kamal = [vectorizer(text).vector for text in name_dict['Kamal Curi']  if 'sticker' not in text  and 'image' not in text]\n",
    "\n",
    "bruno = bruno[:470]\n",
    "kamal = kamal[:470]\n",
    "\n",
    "print(len(bruno), len(kamal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: 'Bruno',\n",
    "    1: 'Kamal',\n",
    "}\n",
    "\n",
    "by = [0 for _ in range(470)]\n",
    "ky = [1 for _ in range(470)]\n",
    "\n",
    "ys = by + ky\n",
    "xs = np.array(bruno + kamal)\n",
    "\n",
    "\n",
    "# Distribuição de classes entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    xs,\n",
    "    ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializa um modelo de K-vizinhos mais próximos\n",
    "# model = KNeighborsClassifier(leaf_size=25, p=1)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "model.fit(list(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Avalia o modelo\n",
    "y_pred = model.predict([X_test[0]])\n",
    "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bruno to vazando\n",
      "Kamal Vazando donde\n",
      "Bruno só assim mesmo pra dar risada\n",
      "Kamal Daquele jeito\n",
      "Bruno o que uma coisa tem haver com a outra?\n",
      "Kamal Jesus Cristo\n",
      "Bruno eu nao tenho uma vida amorosa amigo\n",
      "Kamal hauahauahauahu é foda meu guri\n",
      "Bruno Oh shit\n",
      "Bruno Quem discordar, tá errado.\n",
      "Kamal HAUAHAUAHAUAAJ\n",
      "Bruno eahuhueahuhueahuehua\n",
      "Kamal Tu tá jogando Skyrim agora?\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    'to vazando',  # bruno\n",
    "    'Vazando donde',  # kamal\n",
    "    'só assim mesmo pra dar risada',  # bruno\n",
    "    'Daquele jeito',  # Kamal\n",
    "    'o que uma coisa tem haver com a outra?',  # Bruno\n",
    "    'Jesus Cristo',  # Kamal\n",
    "    'eu nao tenho uma vida amorosa amigo',  # Bruno\n",
    "    'hauahauahauahu é foda meu guri',  # Kamal\n",
    "\n",
    "    'Oh shit',\n",
    "    'Quem discordar, tá errado.',\n",
    "    'HAUAHAUAHAUAAJ',\n",
    "    'eahuhueahuhueahuehua',\n",
    "    'Tu tá jogando Skyrim agora?'\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    text_vector = vectorizer(text).vector\n",
    "    print(classes[model.predict([text_vector])[0]], text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "nn = MLPClassifier(\n",
    "    hidden_layer_sizes=(250, 250),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.01,\n",
    "    power_t=0.5,\n",
    "    max_iter=1000,\n",
    "    shuffle=True,\n",
    "    random_state=None,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    "    warm_start=False,\n",
    "    momentum=0.9,\n",
    "    nesterovs_momentum=True,\n",
    "    early_stopping=False,\n",
    "    validation_fraction=0.1,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-08,\n",
    "    n_iter_no_change=10,\n",
    "    max_fun=15000\n",
    ")\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "pred = nn.predict([X_test[0]])\n",
    "print(f\"test set score: {np.mean(pred == y_test):.2f}\")\n",
    "# print(metrics.precision_score(y_test, pred, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
