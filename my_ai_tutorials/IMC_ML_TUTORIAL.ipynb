{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seasonal-prediction",
   "metadata": {},
   "source": [
    "## IMC com Machine Learning\n",
    "\n",
    "#### Por Bruno Luvizotto Carli\n",
    "\n",
    "*Hello there*,\n",
    "\n",
    "Você tem interesse ou está curioso sobre o crescente campo da Inteligência Artificial, que está se popularizando a cada dia mais?\n",
    "\n",
    "Pretendo demonstrar nesse pequeno tutorial prático, como pode ser simples desenvolver uma aplicação básica de um problema clássico e conhecido, utilizando métodos de machine learnign a partir de um framework que ja nos traz uma gama de ferramentas prontas para realizar inúmeras atividades com machine learning.\n",
    "\n",
    "### IMC\n",
    "\n",
    "Calcular o IMC (Índice de Massa Corporal) é um exercício clássico que grande parte dos iniciantes em programação costumam desenvover. Da forma clássica, nós poderiamos escrever um algoritmo com regras condicionais fixa que realizem a validação lógica a partir de uma entrada, devolvendo então um resultado.\n",
    "\n",
    "Por exemplo, digamos que nossas regras para definição do IMC sejam:\n",
    "\n",
    "- Abaixo do peso: 18 Kg ou menos\n",
    "- Peso ideal: de 19 a 25 Kg;\n",
    "- Sobrepeso: de 26 a 30 kg;\n",
    "- Obesidade: de 31 a 41 Kg;\n",
    "- Obesidade mórbida: Acima de 41 Kg;\n",
    "\n",
    "Seguindo um paradigma clássico de programação, poderiamos implementar estas regras sob uma estrutura condicional, com as regras explicitamente declaradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "turkish-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imc(weight: float) -> str:\n",
    "    if weight <= 18.9:\n",
    "        return 'underweight'\n",
    "    elif 19.0 <= weight <= 25.9:\n",
    "        return 'ideal'\n",
    "    elif 26.0 <= weight <= 30.9:\n",
    "        return 'overweight'\n",
    "    elif 31.0 <= weight <= 41.9:\n",
    "        return 'obesity'\n",
    "    else:\n",
    "        return 'morbid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-mount",
   "metadata": {},
   "source": [
    "Este algoritmo funciona como deveria funcionar, pois programamos explicitamente o algoritmo testar as condições da regra. Podemos provar a função com algumas tentativas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "atlantic-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert imc(9.78) == 'underweight'\n",
    "assert imc(28.976) == 'overweight'\n",
    "assert imc(100) == 'morbid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-hamburg",
   "metadata": {},
   "source": [
    "Essa é uma forma clássica de se resolver este problema. Ao receber um input, a função vai testar cada possibilidade, retornando o resultado caso encontre um valor verdadeiro.\n",
    "\n",
    "Se quiséssemos utilizar uma abordagem baseada em Inteligência Artificial, mais especificamente, selecionando um modelo de machine learning, a interpretação que teriamos de tomar seria um pouco diferente.\n",
    "\n",
    "Ao utiliza machine learning, não informaremos ao programa as regras que definimos anteriormente, vamos deixar que o algoritmo chegue à estas conclusões sozinho.\n",
    "\n",
    "### mas como isso é possível?\n",
    "\n",
    "Resposta: Com dados.\n",
    "\n",
    "Os dados são o fermento natural que o machine learning precisa para fazer \"crescer o seu bolo\". A partir dos dados que tivermos, podemos *ajustar* um modelo para **estimar** a probabilidade de que uma determinada entrada **X** seja da categoria **y**.\n",
    "\n",
    "Como assim?\n",
    "\n",
    "Vamos exemplificar com o mesmo problema do IMC, porém desta vez, não iremos declarar explicitamente as regras condicionais, pelo contrário, vamos gerar varias categorias de dados dentro das faixas.\n",
    "\n",
    "Imagine que nós tivessemo algumas listas de pesos de pessoas reais. As listas estão separadas por faixa de peso da mesma forma que as regras anteriores separam as categorias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "continuing-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos utilizar algumas bibliotecas do Python\n",
    "from random import random, randint\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "occupational-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geramos pesos (Kg) para 1000 pessoas em cada categora, somando 5000 exemplos:\n",
    "underweight = [random() + randint(0, 18) - .5 for _ in range(1000)]\n",
    "ideal = [random() + randint(19, 25) -.5 for _ in range(1000)]\n",
    "overweight = [random() + randint(25, 30) for _ in range(1000)]\n",
    "obesity = [random() + randint(30, 41) - .5 for _ in range(1000)]\n",
    "morbid = [random() + randint(40, 100) for _ in range(1000)]\n",
    "\n",
    "# Nós também geramos a correspondencia aos exemplos gerados\n",
    "underweight_targets = [0 for _ in range(1000)]\n",
    "ideal_targets = [1 for _ in range(1000)]\n",
    "overweight_targets = [2 for _ in range(1000)]\n",
    "obesity_targets = [3 for _ in range(1000)]\n",
    "morbid_targets = [4 for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-strain",
   "metadata": {},
   "source": [
    "## O que é essa correspondência?\n",
    "\n",
    "O Machine Learning somente entende números, então precisamos mapear a categoria que queremos classificar par aum **número**, desta forma mapeamos um inteiro fixo para cada categoria:\n",
    "\n",
    "- `0` -> underweight;\n",
    "- `1` -> ideal;\n",
    "- `2` -> overweight;\n",
    "- `3` -> obesity;\n",
    "- `4` -> morbid;\n",
    "\n",
    "Desta forma, quando nosso algoritmo retornar `3` sabemos que ele classificou a entrada como **obesidade**.\n",
    "\n",
    "Podemos escrever esse mapa com um `dict` python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "polished-chicago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'overweight'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    0: 'underweight',\n",
    "    1: 'ideal',\n",
    "    2: 'overweight',\n",
    "    3: 'obesity',\n",
    "    4: 'morbid'\n",
    "}\n",
    "\n",
    "results.get(2)  # deve retornar sobrepeso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-trace",
   "metadata": {},
   "source": [
    "Resumindo, criamos 1000 dados na faixa de peso de peso de uma categoria, para cada categoria, e da mesma forma, criamos 1000 rótulos para cada categoria, ou seja, 1000 exemplo de peso ideal, teremos uma lista de 1000 números `1`.\n",
    "\n",
    "Agora vamos unir estes dados, precisamos concatenar as listas, gerando uma unica lista de 5000 exemplos ordenados (ordenados pois precisamos mapear para os rótulos) e uma lista com 5000 respostas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "surrounded-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'samples': np.array(low + ideal + overweight + obesity + morbid),\n",
    "    'targets': underweight_targets + ideal_targets + overweight_targets + obesity_targets + morbid_targets,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-deposit",
   "metadata": {},
   "source": [
    "### O que nós queremos com isso?\n",
    "\n",
    "Nós queremos poder ensinar a máquina que cada elemento da lista `samples` corresponde ao seu indice equivalente, da lista `targets`, ou em outras palavras, queremos ensinar o computador, que o elemento em `dataset['samples'][0]` corresponde ao `dataset['targets'][0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "intended-donor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O peso (Kg):  5.58631550444403  corresponde a  underweight\n"
     ]
    }
   ],
   "source": [
    "print('O peso (Kg): ', dataset['samples'][0], ' corresponde a ', results.get(dataset['targets'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-record",
   "metadata": {},
   "source": [
    "Certo, dito isso, vamos aos procedimentos de ensinar a máquina.\n",
    "\n",
    "É muito comum em Machine Learning que os dados sejam divididos em um coinjunto de **treino** e um conjunto de **teste**.\n",
    "\n",
    "O conjunto de **treino** é utilizado para ensinar a máquina, onde ensinar a máquina, significa que vamos mostrar ao algoritmo varios exemplos de dados e a resposta para o exemplo. Da mesma forma que, quando somos crianças, um adulto chega em nossa frente, com uma fruta avermelhada em suas mãos e nos diz: \"Isto é uma maçã\". Estamos a fazer a mesma coisa com o algoritmo, porém com um caminhão de maçãs, peras, melancias e pêssegos. Isto é chamado de **Aprendizado Supervisionado**.\n",
    "\n",
    "![](https://image.slidesharecdn.com/thisisanapple-140802233157-phpapp01/95/this-is-an-apple-2-638.jpg?cb=1407022351)\n",
    "\n",
    "\n",
    "O conjunto de **teste** deve representar uma  parcela de dados que que o algoritmo ainda não viu. Utilizamos este conjunto para medir a capacidade que o algoritmo possui de acertar ou errar uma pergunta que fizermos. Por exemplo, após treinar o algoritmo com varias iomagens de maçãs, peras, melacias e pêssegos, poderiamos chegar com um fruto de forma meio \"arredondada\" de coloração avermelhada e perguntar ao algoritmo: \"O que é isso\".\n",
    "\n",
    "Como nós mostramos ao algoritmo mil exemplos de maçãs com esta característica, nosso hipótese seria de que ele respondesse: \"É uma maçã.\"\n",
    "\n",
    "O scikit ja implementa um método que realiza a separação dos nosso dados em um conjunto de treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bigger-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mistura os dados e separa-os em dados de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset['samples'],\n",
    "    dataset['targets']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-score",
   "metadata": {},
   "source": [
    "Para ete exemplo utilizaremos um modelo chamado KNN (K-Nearest Neighbors) ou em português: *K vizinhos mais próximos*. Este modelo é conhecido por classificar um dado baseado em outros grupos de dados com características semelhantes.\n",
    "\n",
    "Eu sugiro que, após ler este tutorial que você leitor, busque na [documentação do scikit-learn](https://scikit-learn.org/stable/supervised_learning.html) por outros modelos e tente utilizá-los para treinar os mesmos dados e ver o que acontece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "distinct-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa um modelo de K-vizinhos mais próximos\n",
    "knn = KNeighborsClassifier(n_neighbors=3).fit(X_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-ready",
   "metadata": {},
   "source": [
    "Na execução acima nós instanciamos o estimador KNN com o parâmetro `n_neighbors` com valor 3. Isto significa que o classificador vai tentar dar a resposta par aum determinado dado de entrada, a aprtir das carcterísticas dos 3 vizinhos mais próximos deste dado.\n",
    "\n",
    "Ou seja, se eu mostrar ao algoritmo de maçãs e pêras um dado arrendondado e vermelho, o algoritmo vai tentar lembrar de todas as frutas que ele viu, colocar este novo dado próximo de 3 outros exemplos muito parecidos, onde dois deles são maças e um deles é uma pêra. O novo dado se aproxima mais das duas maçãs, logo, o algotitmo infere que, como o novo dado se parece com as maçãs, deve ser uma maçã.\n",
    "\n",
    "O método encadeado `.fit()` é a chamada especial que \"ensina\" o modelo que cada exemplo contido em `X_train` correspodne aos rótulos de `y_train`.\n",
    "\n",
    "Podemos agora testar a precisãod e acerto do modelo com o conjunto de testes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "backed-drink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Avalia o modelo\n",
    "y_pred = knn.predict(X_test.reshape(-1, 1))\n",
    "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-notebook",
   "metadata": {},
   "source": [
    "Nosso modelo acerta com 95% de precisão.\n",
    "\n",
    "Mas aí você pensa \"poxa mas ele não acerta 100%, então é ruim\", bem isso é uma meia verdade. Em Inteligência Artificial, um algoritmo jamais chegará a 100%, e se chegar, deve estar errado. Se um modelo de machine learning acertar com 100% de precisão, isso significa que ele estará **super ajustado**, o que quer dizer que especialmente para os dados que ele conhece, ele acerta 100% das ṕerguntas, mas para dados que ele nunca viu (dados que não existem no dataset de treino) ele não terá capacidade de generalizar e acertar a resposta. Esse é um dos viéses do machine learning que nos permitem brincar com inúmeros parâmetros para ajustar os modelos.\n",
    "\n",
    "Bem chega de blablabla e vamos testar nosso modelo com algumas entradas.\n",
    "\n",
    "Primeiro vamos redefinir nossa função de IMC para retornar o método `predict()` do modelo KNN sobre o peso inserido. Perceba como agora não temos uma \"pilha de IFs\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sustained-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imc(weight: float) -> str:\n",
    "    return results.get(knn.predict([[weight]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "affecting-source",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.4:  underweight\n",
      "17.9:  underweight\n",
      "18.6:  ideal\n",
      "22.0:  ideal\n",
      "28.9:  overweight\n",
      "34:  obesity\n",
      "89.22:  morbid\n"
     ]
    }
   ],
   "source": [
    "print('14.4: ', imc(14.5))\n",
    "print('17.9: ', imc(17.9))\n",
    "print('18.6: ', imc(18.6))\n",
    "print('22.0: ', imc(22.0))\n",
    "print('28.9: ', imc(28.9))\n",
    "print('34: ', imc(34))\n",
    "print('89.22: ', imc(89.22))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-badge",
   "metadata": {},
   "source": [
    "## Concluindo\n",
    "\n",
    "Este é um exercío básico e prático para exemplificar como tarefas clássicas de ciência da computação podem ser facilmente implementadas com Machine Learning. A biblioteca Scikit-Learn ja nos traz vários modelos prontos para usar, facilitando muito trabalho envolvido por baixo dos panos, como cálculos estatísticos e ajustes de parâmetros internos do modelo.\n",
    "\n",
    "Esta implementação é lúdica, dificilmente um modelo desse tamanho seria mais eficiente do que uma implementação clássica com tão poucas condições como este exemplo, mas para grandes sistemas o machine learning pode apresentar um salto enorme em eficiência computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-briefing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
