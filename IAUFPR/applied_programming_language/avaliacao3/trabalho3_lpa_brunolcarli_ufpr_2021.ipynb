{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "innovative-address",
   "metadata": {},
   "source": [
    "# sklearn-assignment\n",
    "\n",
    "### Bruno Luvizotto Carli\n",
    "\n",
    "### IAA2021 - UFPR\n",
    "\n",
    "Atividade proposta na disciplina de Linguagem de Programação Aplicada do curso de Especialização em Inteligência Artfical Aplicada da Universidade Federal do Paraná (UFPR).\n",
    "\n",
    "### Professor: Alexander Robert Kutzke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-triangle",
   "metadata": {},
   "source": [
    "# Original Exercise Author: Olivier Grisel\n",
    "\n",
    "<olivier.grisel@ensta.org>\n",
    "\n",
    "## License: Simplified BSD\n",
    "\n",
    "\n",
    "Build a sentiment analysis / polarity model\n",
    "\n",
    "Sentiment analysis can be casted as a binary text classification problem,\n",
    "that is fitting a linear classifier on features extracted from the text\n",
    "of the user messages so as to guess wether the opinion of the author is\n",
    "positive or negative.\n",
    "\n",
    "In this examples we will use a movie review dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlling-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "falling-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "expired-negative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 2000\n"
     ]
    }
   ],
   "source": [
    "# the training data folder must be passed as first argument\n",
    "movie_reviews_data_folder = r\"./data\"\n",
    "dataset = load_files(movie_reviews_data_folder, shuffle=False)\n",
    "print(\"n_samples: %d\" % len(dataset.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-transcript",
   "metadata": {},
   "source": [
    "#### Lets take a look at the data first.\n",
    "\n",
    "A Pandas Data Frame will be handful here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accessible-chick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'plot : two teen couples go to a church party...</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'the happy bastard\\'s quick movie review \\nda...</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b\"it is movies like these that make a jaded mo...</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b' \" quest for camelot \" is warner bros . \\' f...</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'synopsis : a mentally unstable man undergoin...</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>b\"wow ! what a movie . \\nit's everything a mov...</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>b'richard gere can be a commanding actor , but...</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>b'glory--starring matthew broderick , denzel w...</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>b'steven spielberg\\'s second epic film on worl...</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>b'truman ( \" true-man \" ) burbank is the perfe...</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Data Target\n",
       "0     b'plot : two teen couples go to a church party...   b'0'\n",
       "1     b'the happy bastard\\'s quick movie review \\nda...   b'0'\n",
       "2     b\"it is movies like these that make a jaded mo...   b'0'\n",
       "3     b' \" quest for camelot \" is warner bros . \\' f...   b'0'\n",
       "4     b'synopsis : a mentally unstable man undergoin...   b'0'\n",
       "...                                                 ...    ...\n",
       "1995  b\"wow ! what a movie . \\nit's everything a mov...   b'1'\n",
       "1996  b'richard gere can be a commanding actor , but...   b'1'\n",
       "1997  b'glory--starring matthew broderick , denzel w...   b'1'\n",
       "1998  b'steven spielberg\\'s second epic film on worl...   b'1'\n",
       "1999  b'truman ( \" true-man \" ) burbank is the perfe...   b'1'\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    data= np.c_[dataset.data, dataset.target],\n",
    "    columns=['Data', 'Target']\n",
    ")\n",
    "\n",
    "df  # show information on jupyter notebook output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "material-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in training and test set:\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.25, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "worth-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Build a vectorizer / classifier pipeline that filters out tokens\n",
    "# that are too rare or too frequent\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(docs_train, y_train)\n",
    "\n",
    "# Now we can build a function to extract the tokens from a string\n",
    "def string_filter(text: str, clf: Callable = text_clf.predict) -> Tuple[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Remove all most/less common tokens from a text string.\n",
    "    Returns a tuple in which the first position corresponds\n",
    "    to the inputed string without the tokens and in the\n",
    "    second position a list of the removed tokens.\n",
    "    \"\"\"\n",
    "    tokens: List[str] = text.split()\n",
    "    removed: List[str] = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if clf([token])[0] == 0:\n",
    "            removed.append(tokens.pop(tokens.index(token)))\n",
    "\n",
    "    filtered: str = ' '.join(token for token in tokens).strip()\n",
    "    return filtered, list(set(removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-underwear",
   "metadata": {},
   "source": [
    "Now we can get both a filtered text and also a list of the filtered tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "double-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick brown fox over lazy\n",
      "['jumps', 'the', 'dog']\n"
     ]
    }
   ],
   "source": [
    "filtered_text, removed_tokens = string_filter('the quick brown fox jumps over the lazy dog')\n",
    "print(filtered_text)\n",
    "print(removed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "virgin-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha 0.01\n",
      "tfidf__use_idf False\n",
      "vect__ngram_range (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# TASK: Build a grid search to find out whether unigrams or bigrams are\n",
    "# more useful.\n",
    "# Fit the pipeline on the training set using grid search for the parameters\n",
    "\n",
    "# i will be using the standartd example from the docs\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(docs_train, y_train)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(param_name, gs_clf.best_params_[param_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-ordinary",
   "metadata": {},
   "source": [
    "Lets test our filter with this new classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "brown-century",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick brown fox over lazy\n",
      "['jumps', 'the', 'dog']\n"
     ]
    }
   ],
   "source": [
    "filtered_text, removed_tokens = string_filter('the quick brown fox jumps over the lazy dog', gs_clf.predict)\n",
    "print(filtered_text)\n",
    "print(removed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "removable-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8299999999999998\n"
     ]
    }
   ],
   "source": [
    "# TASK: print the cross-validated scores for the each parameters set\n",
    "# explored by the grid search\n",
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "signal-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.95      0.98      0.97       255\n",
      "         pos       0.98      0.95      0.96       245\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK: Predict the outcome on the testing set and store it in a variable\n",
    "# named y_predicted\n",
    "y_predicted = gs_clf.predict(docs_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "experienced-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[250   5]\n",
      " [ 13 232]]\n"
     ]
    }
   ],
   "source": [
    "# Print and plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "lined-binding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(cm)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
