{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confirmed-pottery",
   "metadata": {},
   "source": [
    "<hr /> \n",
    "\n",
    "## Machine Learning Marathon parte 1\n",
    "\n",
    "```\n",
    "Desafio inspirado em trabalho para disciplina de Aprendizagem de Máquina do curso de Especialização em Inteligência Artificial Aplicada da Universidade Federal do Paraná (UFPR) 2021\n",
    "```\n",
    "\n",
    "<hr /> \n",
    "\n",
    "\n",
    "### Objetivo do desafio\n",
    "\n",
    "Para os datasets:\n",
    "\n",
    "- Volume;\n",
    "- Biomassa;\n",
    "- Admissão;\n",
    "- Alunos Ensino Médio;\n",
    "\n",
    "Treinar os seguintes modelos de **regressão**:\n",
    "\n",
    "- Rede Neural Artificial (com Hold out, cross validation e grid search)\n",
    "- K-Nearest Neighbors\n",
    "- Support Vector Machine (Com hold out, cross validation e grid search)\n",
    "- Random Forest (com hold out, cross validation e grid search)\n",
    "\n",
    "Apresentando em uma tabela, todos os modelos elencando as seguintes métricas de regressão:\n",
    "\n",
    "- Parâmetros do modelo;\n",
    "- R2\n",
    "- Syx\n",
    "- Correlação de Pearson\n",
    "- RMSE\n",
    "- MAE\n",
    "\n",
    "<hr />\n",
    "\n",
    " Observações:\n",
    " \n",
    "- A tabela de modelos para cada dataset deve ser ordenada por maior R2;\n",
    "- Apresentar um gráfico de residuos para cada tabela para o modelo de maior R2;\n",
    "\n",
    "<hr /> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attempted-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modulos e bibliotecas necessários\n",
    "\n",
    "# Visualização\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# modelos\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# métricas de regressão\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "# Opta por utilziar a visualização linda do seaborn <3\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "roman-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define os caminhos para os arquivos de dados em um dicionário\n",
    "files = {\n",
    "    'volume': 'datasets/volume/Material 02 - 3 – Estimativa de Volume - Dados.csv',\n",
    "    'biomassa': 'datasets/biomass/Material 02 - 4 - R - Biomassa - Dados.csv',\n",
    "    'admissao': 'datasets/admissao/Material 02 - 8 – R - Admissao - Dados.csv',\n",
    "    'alunos_em': 'datasets/alunos_em/Material 02 - 10 – Alunos - Dados.csv'\n",
    "}\n",
    "\n",
    "# Funções de métricas manualmente implementadas\n",
    "def r2(predicted, target):\n",
    "    return 1 - (sum((predicted - target)**2) / sum((predicted - np.mean(target)**2)))\n",
    "\n",
    "# Syx\n",
    "def syx(predicted, target, feature_size):\n",
    "    return  sum((predicted - target)**2) / (len(target) - feature_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-douglas",
   "metadata": {},
   "source": [
    "<hr /> \n",
    "\n",
    "# Dataset 1 - Volume\n",
    "\n",
    "<hr /> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broke-accent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROJETO</th>\n",
       "      <th>CLONE</th>\n",
       "      <th>Idade</th>\n",
       "      <th>Hdom</th>\n",
       "      <th>AreaBasal</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fazenda Velha</td>\n",
       "      <td>C3</td>\n",
       "      <td>21.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fazenda Velha</td>\n",
       "      <td>A3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>66.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fazenda Velha</td>\n",
       "      <td>A3</td>\n",
       "      <td>26.1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fazenda Velha</td>\n",
       "      <td>A4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>35.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parada</td>\n",
       "      <td>B7</td>\n",
       "      <td>23.4</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PROJETO CLONE  Idade  Hdom  AreaBasal  Volume\n",
       "0  Fazenda Velha    C3   21.5   8.8        3.2    12.1\n",
       "1  Fazenda Velha    A3   21.9  10.2        3.9    66.8\n",
       "2  Fazenda Velha    A3   26.1  10.1        4.2    72.1\n",
       "3  Fazenda Velha    A4   22.0  10.0        4.2    35.9\n",
       "4         Parada    B7   23.4  15.3        4.3    44.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_df = pd.read_csv(files['volume'])\n",
    "volume_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-battle",
   "metadata": {},
   "source": [
    "## Criação da partição de dados\n",
    "<br />\n",
    "Os dados serão divididos em 80% para treino e 20% para teste.\n",
    "\n",
    "- Desconsiderou-se as variáveis categóricas `PROJETO` e `CLONE`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "painful-albany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape  (244, 3)\n",
      "Train y shape  (244,)\n",
      "Test X shape  (62, 3)\n",
      "Test y shape  (62,)\n"
     ]
    }
   ],
   "source": [
    "volume_X_train, volume_X_test, volume_y_train, volume_y_test = train_test_split(\n",
    "    volume_df[['Idade', 'Hdom', 'AreaBasal']].values,\n",
    "    volume_df.Volume,\n",
    "    test_size=0.2,\n",
    "    random_state=2154\n",
    ")\n",
    "\n",
    "# Exibe os shapes das partições\n",
    "print('Train X shape ', volume_X_train.shape)\n",
    "print('Train y shape ', volume_y_train.shape)\n",
    "print('Test X shape ', volume_X_test.shape)\n",
    "print('Test y shape ', volume_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-minutes",
   "metadata": {},
   "source": [
    "## Rede Neural Artificial\n",
    "<br />\n",
    " A rede neural utilizada será uma *Multi Layer Perceptron Regressor (MLP REGRESSOR)* do sci-kit learn\n",
    " \n",
    " A rede será treinada com os métodos:\n",
    " - *Hold out*\n",
    " - *Cross Validation*\n",
    " - *Grid Search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "authorized-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Inicializa uma coleção de RNAs a se preencher\n",
    "volume_mlps = {\n",
    "    'mlp_hold_out': [],\n",
    "    'mlp_cross_val': [],\n",
    "    'mlp_grid_search': []\n",
    "}\n",
    "\n",
    "# MLP hold out\n",
    "volume_mlp = MLPRegressor(random_state=2154)\n",
    "volume_mlp.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "# MLP com cros val\n",
    "volume_cv_mlp = GridSearchCV(volume_mlp, param_grid={}, cv=10)\n",
    "volume_cv_mlp.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "# MLP com grid\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(1, 5, 10), (50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "volume_grid_mlp = GridSearchCV(volume_mlp, parameter_space, n_jobs=-1, cv=10)\n",
    "volume_grid_mlp.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "mlps = [volume_mlp, volume_cv_mlp, volume_grid_mlp]\n",
    "\n",
    "# Métricas\n",
    "for key, model in zip(volume_mlps.keys(), mlps):\n",
    "    # Parametros\n",
    "    predicts = model.predict(volume_X_test)\n",
    "    # R2 Manual\n",
    "    volume_mlps[key].append(r2(predicts, volume_y_test))\n",
    "    # R2 do sklearn\n",
    "    volume_mlps[key].append(r2_score(predicts, volume_y_test))\n",
    "    # SYX\n",
    "    volume_mlps[key].append(syx(predicts, volume_y_test, len(volume_X_test[0])))\n",
    "    # Pearson\n",
    "    volume_mlps[key].append(pearsonr(volume_y_test, predicts)[0])\n",
    "    # RMSE\n",
    "    volume_mlps[key].append(np.sqrt(mean_squared_error(volume_y_test, predicts)))\n",
    "    # MAE\n",
    "    volume_mlps[key].append(mean_absolute_error(volume_y_test, predicts))\n",
    "\n",
    "\n",
    "# parametros dos modelos\n",
    "volume_mlps['mlp_hold_out'].insert(0, {\n",
    "    'size': volume_mlp.get_params()['hidden_layer_sizes'],\n",
    "    'alpha': volume_mlp.get_params()['alpha'],\n",
    "})\n",
    "volume_mlps['mlp_cross_val'].insert(0, {\n",
    "    'size': volume_cv_mlp.estimator.get_params()['hidden_layer_sizes'],\n",
    "    'alpha': volume_cv_mlp.estimator.get_params()['alpha'],\n",
    "})\n",
    "volume_mlps['mlp_grid_search'].insert(0, {\n",
    "    'size': volume_grid_mlp.best_params_['hidden_layer_sizes'],\n",
    "    'alpha': volume_grid_mlp.best_params_['alpha'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-merchandise",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "<br />\n",
    "\n",
    "Treinar o KNN com:\n",
    "- *Grid Search*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "portuguese-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Treina a KNN\n",
    "volume_knn = KNeighborsRegressor()\n",
    "volume_knn = GridSearchCV(volume_knn, {'n_neighbors': [1, 3, 5, 7, 9]}, n_jobs=-1, cv=10)\n",
    "volume_knn.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "# predicts\n",
    "knn_predicts = volume_knn.predict(volume_X_test)\n",
    "\n",
    "knn_metrics = {\n",
    "    'knn': [\n",
    "        {'k': volume_knn.best_params_['n_neighbors']},\n",
    "        r2(knn_predicts, volume_y_test),  # R2 Manual\n",
    "        r2_score(knn_predicts, volume_y_test),  # R2 do sklearn\n",
    "        syx(knn_predicts, volume_y_test, len(volume_X_test[0])),  # SYX\n",
    "        pearsonr(volume_y_test, knn_predicts)[0],  # Pearson\n",
    "        np.sqrt(mean_squared_error(volume_y_test, knn_predicts)), # RMSE\n",
    "        mean_absolute_error(volume_y_test, knn_predicts)  # MAE\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-spell",
   "metadata": {},
   "source": [
    "## Support Vector Machine -  SVR\n",
    "<br />\n",
    " A SVM utilizada será a *Support Vector Regressor* disponibilizada pelo SKlearn\n",
    " \n",
    " A SVR será treinada com os métodos:\n",
    " - *Hold out*\n",
    " - *Cross Validation*\n",
    " - *Grid Search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adequate-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Inicializa uma coleção de SVMs a se preencher\n",
    "volume_svms = {\n",
    "    'svm_hold_out': [],\n",
    "    'svm_cross_val': [],\n",
    "    'svm_grid_search': []\n",
    "}\n",
    "\n",
    "# SVR hold out\n",
    "volume_svr = SVR()\n",
    "volume_svr.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "# SVR com cross val\n",
    "volume_cv_svr = GridSearchCV(volume_svr, param_grid={}, cv=10)\n",
    "volume_cv_svr.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "# SVR com grid\n",
    "param_grid = [\n",
    "    {\n",
    "        'C': [2.0, 2.1, 2.2, 2.5, 2.7, 3.0, 4.0, 5.0, 50],\n",
    "        'degree': [-1, 1, 1.5, 2, 3, 4, 5],\n",
    "        'epsilon': [0.1, 0.2, 0.3, 0.5, 0.7]\n",
    "    },\n",
    "]\n",
    "volume_grid_svr = GridSearchCV(volume_svr, param_grid, n_jobs=-1, cv=10)\n",
    "volume_grid_svr.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "\n",
    "svrs = [volume_svr, volume_cv_svr, volume_grid_svr]\n",
    "\n",
    "# Métricas\n",
    "for key, model in zip(volume_svms.keys(), svrs):\n",
    "    predicts = model.predict(volume_X_test)\n",
    "    # R2 Manual\n",
    "    volume_svms[key].append(r2(predicts, volume_y_test))\n",
    "    # R2 do sklearn\n",
    "    volume_svms[key].append(r2_score(predicts, volume_y_test))\n",
    "    # SYX\n",
    "    volume_svms[key].append(syx(predicts, volume_y_test, len(volume_X_test[0])))\n",
    "    # Pearson\n",
    "    volume_svms[key].append(pearsonr(volume_y_test, predicts)[0])\n",
    "    # RMSE\n",
    "    volume_svms[key].append(np.sqrt(mean_squared_error(volume_y_test, predicts)))\n",
    "    # MAE\n",
    "    volume_svms[key].append(mean_absolute_error(volume_y_test, predicts))\n",
    "\n",
    "\n",
    "# Parametros dos modelos\n",
    "volume_svms['svm_hold_out'].insert(0, {\n",
    "    'C': volume_svr.get_params()['C'],\n",
    "    'epsilon': volume_svr.get_params()['epsilon'],\n",
    "})\n",
    "volume_svms['svm_cross_val'].insert(0, {\n",
    "    'C': volume_cv_svr.estimator.get_params()['C'],\n",
    "    'epsilon': volume_cv_svr.estimator.get_params()['epsilon'],\n",
    "})\n",
    "volume_svms['svm_grid_search'].insert(0, {\n",
    "    'C': volume_grid_svr.best_params_['C'],\n",
    "    'epsilon': volume_grid_svr.best_params_['epsilon'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-prisoner",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "<br />\n",
    " A Floresta Aleatória utilizada será a *Random Forest Regressor* disponibilizada pelo SKlearn\n",
    " \n",
    " A RF será treinada com os métodos:\n",
    " - *Hold out*\n",
    " - *Cross Validation*\n",
    " - *Grid Search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "convertible-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Inicializa uma coleção de RF a se preencher\n",
    "volume_rfs = {\n",
    "    'rf_hold_out': [],\n",
    "    'rf_cross_val': [],\n",
    "    'rf_grid_search': []\n",
    "}\n",
    "\n",
    "# RF hold out\n",
    "volume_rf = RandomForestRegressor()\n",
    "volume_rf.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "# RF com cross val\n",
    "volume_cv_rf = GridSearchCV(volume_rf, param_grid={}, cv=10)\n",
    "volume_cv_rf.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [10, 50, 100, 200, 500],\n",
    "        'max_depth': [1, 2, 3, 4, 5],\n",
    "    },\n",
    "]\n",
    "volume_grid_rf = GridSearchCV(volume_rf, param_grid, n_jobs=-1, cv=10)\n",
    "volume_grid_rf.fit(volume_X_train, volume_y_train)\n",
    "\n",
    "rfs = [volume_rf, volume_cv_rf, volume_grid_rf]\n",
    "\n",
    "# Métricas\n",
    "for key, predicts in zip(volume_rfs.keys(), rfs):\n",
    "    predicts = model.predict(volume_X_test)\n",
    "    # R2 Manual\n",
    "    volume_rfs[key].append(r2(predicts, volume_y_test))\n",
    "    # R2 do sklearn\n",
    "    volume_rfs[key].append(r2_score(predicts, volume_y_test))\n",
    "    # SYX\n",
    "    volume_rfs[key].append(syx(predicts, volume_y_test, len(volume_X_test[0])))\n",
    "    # Pearson\n",
    "    volume_rfs[key].append(pearsonr(volume_y_test, predicts)[0])\n",
    "    # RMSE\n",
    "    volume_rfs[key].append(np.sqrt(mean_squared_error(volume_y_test, predicts)))\n",
    "    # MAE\n",
    "    volume_rfs[key].append(mean_absolute_error(volume_y_test, predicts))\n",
    "\n",
    "# Parametros dos modelos\n",
    "volume_rfs['rf_hold_out'].insert(0, {\n",
    "    'n_estimators': volume_rf.get_params()['n_estimators'],\n",
    "    'max_depth': volume_rf.get_params()['max_depth'],\n",
    "})\n",
    "volume_rfs['rf_cross_val'].insert(0, {\n",
    "    'n_estimators': volume_cv_rf.estimator.get_params()['n_estimators'],\n",
    "    'max_depth': volume_cv_rf.estimator.get_params()['max_depth'],\n",
    "})\n",
    "volume_rfs['rf_grid_search'].insert(0, {\n",
    "    'n_estimators': volume_grid_rf.best_params_['n_estimators'],\n",
    "    'max_depth': volume_grid_rf.best_params_['max_depth'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-flour",
   "metadata": {},
   "source": [
    "## Agrupando a tabela de modelos para o dataset Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fantastic-sender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Params</th>\n",
       "      <th>R2 Manual</th>\n",
       "      <th>R2 Sklearn</th>\n",
       "      <th>SYX</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm_hold_out</th>\n",
       "      <td>{'C': 1.0, 'epsilon': 0.1}</td>\n",
       "      <td>1.153781</td>\n",
       "      <td>-12.514327</td>\n",
       "      <td>21882.144318</td>\n",
       "      <td>0.827616</td>\n",
       "      <td>144.302914</td>\n",
       "      <td>120.166135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_cross_val</th>\n",
       "      <td>{'C': 1.0, 'epsilon': 0.1}</td>\n",
       "      <td>1.153781</td>\n",
       "      <td>-12.514327</td>\n",
       "      <td>21882.144318</td>\n",
       "      <td>0.827616</td>\n",
       "      <td>144.302914</td>\n",
       "      <td>120.166135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_grid_search</th>\n",
       "      <td>{'C': 50, 'epsilon': 0.7}</td>\n",
       "      <td>1.082198</td>\n",
       "      <td>0.589168</td>\n",
       "      <td>11693.0762</td>\n",
       "      <td>0.845593</td>\n",
       "      <td>105.485934</td>\n",
       "      <td>82.047433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_hold_out</th>\n",
       "      <td>{'n_estimators': 100, 'max_depth': None}</td>\n",
       "      <td>1.082198</td>\n",
       "      <td>0.589168</td>\n",
       "      <td>11693.0762</td>\n",
       "      <td>0.845593</td>\n",
       "      <td>105.485934</td>\n",
       "      <td>82.047433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_cross_val</th>\n",
       "      <td>{'n_estimators': 100, 'max_depth': None}</td>\n",
       "      <td>1.082198</td>\n",
       "      <td>0.589168</td>\n",
       "      <td>11693.0762</td>\n",
       "      <td>0.845593</td>\n",
       "      <td>105.485934</td>\n",
       "      <td>82.047433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_grid_search</th>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 4}</td>\n",
       "      <td>1.082198</td>\n",
       "      <td>0.589168</td>\n",
       "      <td>11693.0762</td>\n",
       "      <td>0.845593</td>\n",
       "      <td>105.485934</td>\n",
       "      <td>82.047433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_hold_out</th>\n",
       "      <td>{'size': (100,), 'alpha': 0.0001}</td>\n",
       "      <td>1.070423</td>\n",
       "      <td>0.500642</td>\n",
       "      <td>10019.346045</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>97.644964</td>\n",
       "      <td>75.697968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_cross_val</th>\n",
       "      <td>{'size': (100,), 'alpha': 0.0001}</td>\n",
       "      <td>1.070423</td>\n",
       "      <td>0.500642</td>\n",
       "      <td>10019.346045</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>97.644964</td>\n",
       "      <td>75.697968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_grid_search</th>\n",
       "      <td>{'size': (100,), 'alpha': 0.05}</td>\n",
       "      <td>1.070294</td>\n",
       "      <td>0.501599</td>\n",
       "      <td>10001.102586</td>\n",
       "      <td>0.846675</td>\n",
       "      <td>97.556026</td>\n",
       "      <td>75.692644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>{'k': 7}</td>\n",
       "      <td>1.06526</td>\n",
       "      <td>0.670183</td>\n",
       "      <td>9284.351038</td>\n",
       "      <td>0.868762</td>\n",
       "      <td>93.995257</td>\n",
       "      <td>75.491475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Params R2 Manual  \\\n",
       "svm_hold_out                   {'C': 1.0, 'epsilon': 0.1}  1.153781   \n",
       "svm_cross_val                  {'C': 1.0, 'epsilon': 0.1}  1.153781   \n",
       "svm_grid_search                 {'C': 50, 'epsilon': 0.7}  1.082198   \n",
       "rf_hold_out      {'n_estimators': 100, 'max_depth': None}  1.082198   \n",
       "rf_cross_val     {'n_estimators': 100, 'max_depth': None}  1.082198   \n",
       "rf_grid_search      {'n_estimators': 200, 'max_depth': 4}  1.082198   \n",
       "mlp_hold_out            {'size': (100,), 'alpha': 0.0001}  1.070423   \n",
       "mlp_cross_val           {'size': (100,), 'alpha': 0.0001}  1.070423   \n",
       "mlp_grid_search           {'size': (100,), 'alpha': 0.05}  1.070294   \n",
       "knn                                              {'k': 7}   1.06526   \n",
       "\n",
       "                R2 Sklearn           SYX   Pearson        RMSE         MAE  \n",
       "svm_hold_out    -12.514327  21882.144318  0.827616  144.302914  120.166135  \n",
       "svm_cross_val   -12.514327  21882.144318  0.827616  144.302914  120.166135  \n",
       "svm_grid_search   0.589168    11693.0762  0.845593  105.485934   82.047433  \n",
       "rf_hold_out       0.589168    11693.0762  0.845593  105.485934   82.047433  \n",
       "rf_cross_val      0.589168    11693.0762  0.845593  105.485934   82.047433  \n",
       "rf_grid_search    0.589168    11693.0762  0.845593  105.485934   82.047433  \n",
       "mlp_hold_out      0.500642  10019.346045  0.846014   97.644964   75.697968  \n",
       "mlp_cross_val     0.500642  10019.346045  0.846014   97.644964   75.697968  \n",
       "mlp_grid_search   0.501599  10001.102586  0.846675   97.556026   75.692644  \n",
       "knn               0.670183   9284.351038  0.868762   93.995257   75.491475  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_models = pd.DataFrame()\n",
    "volume_collections = [volume_mlps, volume_svms, volume_rfs, knn_metrics]\n",
    "\n",
    "for collection in volume_collections:\n",
    "    volume_models = volume_models.append(pd.DataFrame.from_dict(collection).T)\n",
    "\n",
    "volume_models.columns = ['Params', 'R2 Manual', 'R2 Sklearn', 'SYX', 'Pearson', 'RMSE', 'MAE']\n",
    "volume_models.sort_values(by=['R2 Manual'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-coordination",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "# Dataset 2 - Biomassa\n",
    "\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-liberal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-research",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
